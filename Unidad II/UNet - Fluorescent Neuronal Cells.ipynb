{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e826f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn as nn\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import time\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "\n",
    "# modelo UNet\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        \n",
    "        self.encoder1 = self._block(in_channels, 32)  \n",
    "        self.encoder2 = self._block(32, 64)         \n",
    "        self.encoder3 = self._block(64, 128)        \n",
    "\n",
    "        # Capas de decodificador\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self._block(128, 64)  \n",
    "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self._block(64, 32)   \n",
    "        self.decoder1 = self._block(32, out_channels, final_layer=True)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def _block(self, in_channels, features, final_layer=False):\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(features, features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if final_layer:\n",
    "            layers.append(nn.Conv2d(features, out_channels, kernel_size=1))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        \n",
    "        # decoder\n",
    "        dec3 = self.upconv3(enc3)\n",
    "        dec3 = torch.cat((dec3, enc2), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc1), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.decoder1(dec2)\n",
    "        \n",
    "        return dec1\n",
    "    \n",
    "# crear el dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_folder)\n",
    "        self.masks = os.listdir(mask_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.images[idx])\n",
    "        mask_name = os.path.join(self.mask_folder, self.masks[idx])\n",
    "\n",
    "    \n",
    "        image = Image.open(img_name).convert('L') # cambiar depende de los canales\n",
    "        mask = Image.open(mask_name).convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# transformacion de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# dataset y dataloader\n",
    "custom_dataset = CustomDataset(image_folder='C:/tesis/imagenes/imagenes', mask_folder='C:/tesis/imagenes/mascaras', transform=transform)\n",
    "train_ratio = 0.8 \n",
    "train_size = int(train_ratio * len(custom_dataset))\n",
    "val_size = len(custom_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "batch_size = 8 # cambiar lotes\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "in_channels = 1  \n",
    "out_channels = 1  \n",
    "model = UNet(in_channels, out_channels).to(device=device)\n",
    "x = torch.randn((1, in_channels, 512, 512)).to(device) # canales y pixeles\n",
    "predictions = model(x)\n",
    "\n",
    "# funcion para calcular accuracy\n",
    "def calculate_accuracy(predictions, masks):\n",
    "    binary_predictions = (predictions > 0.5).float()\n",
    "    correct = (binary_predictions == masks).float().sum()\n",
    "    total = masks.numel()\n",
    "    accuracy = correct / total\n",
    "    return accuracy.item()\n",
    "\n",
    "# Función para calcular la precisión\n",
    "def calculate_precision(predictions, masks):\n",
    "    binary_predictions = (predictions > 0.5).float()\n",
    "    TP = ((binary_predictions == 1) & (masks == 1)).float().sum()\n",
    "    FP = ((binary_predictions == 1) & (masks == 0)).float().sum()\n",
    "    precision = TP / (TP + FP + 1e-8)  \n",
    "    return precision.item()\n",
    "\n",
    "# entrenamiento del modelo\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_precisions = []\n",
    "val_precisions = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "num_epochs = 100 # ajustar epocas\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0.0\n",
    "    total_train_accuracy = 0.0\n",
    "    total_train_precision = 0.0\n",
    "\n",
    "    # Entrenamiento\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = calculate_accuracy(outputs, masks)\n",
    "        precision = calculate_precision(outputs, masks)\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_accuracy += accuracy\n",
    "        total_train_precision += precision\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_accuracy = total_train_accuracy / len(train_loader)\n",
    "    avg_train_precision = total_train_precision / len(train_loader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_precisions.append(avg_train_precision)\n",
    "\n",
    "    total_val_loss = 0.0\n",
    "    total_val_accuracy = 0.0\n",
    "    total_val_precision = 0.0\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in val_loader:\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss = criterion(val_outputs, val_masks)\n",
    "\n",
    "            accuracy = calculate_accuracy(val_outputs, val_masks)\n",
    "            precision = calculate_precision(val_outputs, val_masks)\n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_accuracy += accuracy\n",
    "            total_val_precision += precision\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_val_accuracy = total_val_accuracy / len(val_loader)\n",
    "    avg_val_precision = total_val_precision / len(val_loader)\n",
    "    \n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_precisions.append(avg_val_precision)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Loss: {avg_train_loss:.4f}, '\n",
    "          f'Prec: {avg_train_precision:.4f}, '\n",
    "          f'Acc: {avg_train_accuracy:.4f}, '\n",
    "          f'Val_Loss: {avg_val_loss:.4f}, '\n",
    "          f'Val_Prec: {avg_val_precision:.4f}, '\n",
    "          f'Val_Acc: {avg_val_accuracy:.4f}, '\n",
    "          f'Time: {epoch_time:.2f} sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_losses, label='Pérdida de Entrenamiento')\n",
    "plt.plot(val_losses, label='Pérdida de Validación')\n",
    "plt.title('Función de Pérdida durante el Entrenamiento y la Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_precisions, label='Precisión de Entrenamiento')\n",
    "plt.plot(val_precisions, label='Precisión de Validación')\n",
    "plt.title('Precisión durante el Entrenamiento y la Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sensitivity(TP, FN):\n",
    "    return TP / (TP + FN + 1e-8)\n",
    "\n",
    "def calculate_specificity(TN, FP):\n",
    "    return TN / (TN + FP + 1e-8)\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "def calculate_confusion_matrix(predictions, masks):\n",
    "    binary_predictions = (predictions > 0.5).float()\n",
    "    TP = ((binary_predictions == 1) & (masks == 1)).float().sum().item()\n",
    "    FP = ((binary_predictions == 1) & (masks == 0)).float().sum().item()\n",
    "    TN = ((binary_predictions == 0) & (masks == 0)).float().sum().item()\n",
    "    FN = ((binary_predictions == 0) & (masks == 1)).float().sum().item()\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def calculate_precision(TP, FP):\n",
    "    precision = TP / (TP + FP + 1e-8)  # Añadido 1e-8 para evitar división por cero\n",
    "    return precision\n",
    "\n",
    "total_val_TP = 0.0\n",
    "total_val_FP = 0.0\n",
    "total_val_TN = 0.0\n",
    "total_val_FN = 0.0\n",
    "\n",
    "# Validación\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for val_images, val_masks in val_loader:\n",
    "        val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "        val_outputs = model(val_images)\n",
    "\n",
    "        TP, FP, TN, FN = calculate_confusion_matrix(val_outputs, val_masks)\n",
    "        total_val_TP += TP\n",
    "        total_val_FP += FP\n",
    "        total_val_TN += TN\n",
    "        total_val_FN += FN\n",
    "\n",
    "# Calcula las métricas finales\n",
    "val_precision = calculate_precision(total_val_TP, total_val_FP)\n",
    "val_recall = calculate_sensitivity(total_val_TP, total_val_FN)  # Sensibilidad\n",
    "val_specificity = calculate_specificity(total_val_TN, total_val_FP)\n",
    "val_f1_score = calculate_f1_score(val_precision, val_recall)\n",
    "\n",
    "print(f'Precision: {val_precision:.4f}, Sensibilidad: {val_recall:.4f}, '\n",
    "      f'Especificidad: {val_specificity:.4f}, F1-Score: {val_f1_score:.4f}')\n",
    "print(f'Matriz de Confusión: Verdaderos Positivos={total_val_TP}, Falsos Positivos={total_val_FP}, Verdaderos Negativos={total_val_TN}, Falsos Negativos={total_val_FN}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
